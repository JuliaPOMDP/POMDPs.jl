<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Concepts and Architecture · POMDPs.jl</title><meta name="title" content="Concepts and Architecture · POMDPs.jl"/><meta property="og:title" content="Concepts and Architecture · POMDPs.jl"/><meta property="twitter:title" content="Concepts and Architecture · POMDPs.jl"/><meta name="description" content="Documentation for POMDPs.jl."/><meta property="og:description" content="Documentation for POMDPs.jl."/><meta property="twitter:description" content="Documentation for POMDPs.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="POMDPs.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">POMDPs.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><span class="tocitem">Basics</span><ul><li><a class="tocitem" href="../">POMDPs.jl</a></li><li><a class="tocitem" href="../install/">Installation</a></li><li><a class="tocitem" href="../get_started/">Getting Started</a></li><li class="is-active"><a class="tocitem" href>Concepts and Architecture</a><ul class="internal"><li><a class="tocitem" href="#POMDPs-and-MDPs"><span>POMDPs and MDPs</span></a></li><li><a class="tocitem" href="#Beliefs-and-Updaters"><span>Beliefs and Updaters</span></a></li><li><a class="tocitem" href="#Solvers-and-Policies"><span>Solvers and Policies</span></a></li><li><a class="tocitem" href="#Simulators"><span>Simulators</span></a></li></ul></li></ul></li><li><span class="tocitem">Defining (PO)MDP Models</span><ul><li><a class="tocitem" href="../def_pomdp/">Defining POMDPs and MDPs</a></li><li><a class="tocitem" href="../interfaces/">Spaces and Distributions</a></li></ul></li><li><span class="tocitem">Writing Solvers</span><ul><li><a class="tocitem" href="../def_solver/">Solvers</a></li><li><a class="tocitem" href="../offline_solver/">Example: Defining an offline solver</a></li><li><a class="tocitem" href="../online_solver/">Example: Defining an online solver</a></li></ul></li><li><span class="tocitem">Writing Belief Updaters</span><ul><li><a class="tocitem" href="../def_updater/">Defining a Belief Updater</a></li></ul></li><li><span class="tocitem">Analyzing Results</span><ul><li><a class="tocitem" href="../simulation/">Simulation Standard</a></li><li><a class="tocitem" href="../run_simulation/">Running Simulations</a></li><li><a class="tocitem" href="../policy_interaction/">Interacting with Policies</a></li></ul></li><li><span class="tocitem">POMDPTools</span><ul><li><a class="tocitem" href="../POMDPTools/">POMDPTools: the standard library for POMDPs.jl</a></li><li><a class="tocitem" href="../POMDPTools/distributions/">Implemented Distributions</a></li><li><a class="tocitem" href="../POMDPTools/model/">Model Tools</a></li><li><a class="tocitem" href="../POMDPTools/visualization/">Visualization</a></li><li><a class="tocitem" href="../POMDPTools/beliefs/">Implemented Belief Updaters</a></li><li><a class="tocitem" href="../POMDPTools/policies/">Implemented Policies</a></li><li><a class="tocitem" href="../POMDPTools/simulators/">Implemented Simulators</a></li><li><a class="tocitem" href="../POMDPTools/common_rl/">CommonRLInterface Integration</a></li><li><a class="tocitem" href="../POMDPTools/testing/">Testing</a></li></ul></li><li><a class="tocitem" href="../faq/">Frequently Asked Questions (FAQ)</a></li><li><a class="tocitem" href="../api/">API Documentation</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Basics</a></li><li class="is-active"><a href>Concepts and Architecture</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Concepts and Architecture</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaPOMDP/POMDPs.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaPOMDP/POMDPs.jl/blob/master/docs/src/concepts.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Concepts-and-Architecture"><a class="docs-heading-anchor" href="#Concepts-and-Architecture">Concepts and Architecture</a><a id="Concepts-and-Architecture-1"></a><a class="docs-heading-anchor-permalink" href="#Concepts-and-Architecture" title="Permalink"></a></h1><p>POMDPs.jl aims to coordinate the development of three software components: 1) a problem, 2) a solver, 3) an experiment. Each of these components has a set of abstract types associated with it and a set of functions that allow a user to define each component&#39;s behavior in a standardized way. An outline of the architecture is shown below.</p><p><img src="../figures/concepts.png" alt="concepts"/></p><p>The MDP and POMDP types are associated with the problem definition. The Solver and Policy types are associated with the solver or decision-making agent. Typically, the Updater type is also associated with the solver, but a solver may sometimes be used with an updater that was implemented separately. The Simulator type is associated with the experiment.</p><p>The code components of the POMDPs.jl ecosystem relevant to problems and solvers are shown below. The arrows represent the flow of information from the problems to the solvers. The figure shows the two interfaces that form POMDPs.jl - Explicit and Generative. Details about these interfaces can be found in the section on <a href="../def_pomdp/#defining_pomdps">Defining POMDPs</a>.</p><p><img src="../figures/interface_relationships.svg" alt="interface_relationships"/></p><h2 id="POMDPs-and-MDPs"><a class="docs-heading-anchor" href="#POMDPs-and-MDPs">POMDPs and MDPs</a><a id="POMDPs-and-MDPs-1"></a><a class="docs-heading-anchor-permalink" href="#POMDPs-and-MDPs" title="Permalink"></a></h2><p>An MDP is a mathematical framework for sequential decision making under uncertainty, and where all of the uncertainty arises from outcomes that are partially random and partially under the control of a decision maker. Mathematically, an MDP is a tuple <span>$(S,A,T,R,\gamma)$</span>, where <span>$S$</span> is the state space, <span>$A$</span> is the action space, <span>$T$</span> is a transition function defining the probability of transitioning to each state given the state and action at the previous time, and <span>$R$</span> is a reward function mapping every possible transition <span>$(s,a,s&#39;)$</span> to a real reward value. Finally, <span>$\gamma$</span> is a discount factor that defines the relative weighting of current and future rewards. For more information see a textbook such as [1]. In POMDPs.jl an MDP is represented by a concrete subtype of the <a href="../api/#POMDPs.MDP"><code>MDP</code></a> abstract type and a set of methods that define each of its components as described in the <a href="../def_pomdp/#defining_pomdps">problem definition section</a>.</p><p>A POMDP is a more general sequential decision making problem in which the agent is not sure what state they are in. The state is only partially observable by the decision making agent. Mathematically, a POMDP is a tuple <span>$(S,A,T,R,O,Z,\gamma)$</span> where <span>$S$</span>, <span>$A$</span>, <span>$T$</span>, <span>$R$</span>, and <span>$\gamma$</span> have the same meaning as in an MDP, <span>$O$</span> is the agent&#39;s observation space, and <span>$Z$</span> defines the probability of receiving each observation at a transition. In POMDPs.jl, a POMDP is represented by a concrete subtype of the <a href="../api/#POMDPs.POMDP"><code>POMDP</code></a> abstract type, and the methods described in the <a href="../def_pomdp/#defining_pomdps">problem definition section</a>.</p><p>POMDPs.jl contains additional functions for defining optional problem behavior such as an <a href="../def_pomdp/#Initial-state-distribution">initial state distribution</a> or <a href="../def_pomdp/#Terminal-states">terminal states</a>. More information can be found in the <a href="../def_pomdp/#defining_pomdps">Defining POMDPs</a> section.</p><h2 id="Beliefs-and-Updaters"><a class="docs-heading-anchor" href="#Beliefs-and-Updaters">Beliefs and Updaters</a><a id="Beliefs-and-Updaters-1"></a><a class="docs-heading-anchor-permalink" href="#Beliefs-and-Updaters" title="Permalink"></a></h2><p>In a POMDP domain, the decision-making agent does not have complete information about the state of the problem, so the agent can only make choices based on its &quot;belief&quot; about the state. In the POMDP literature, the term &quot;belief&quot; is typically defined to mean a probability distribution over all possible states of the system. However, in practice, the agent often makes decisions based on an incomplete or lossy record of past observations that has a structure much different from a probability distribution. For example, if the agent is represented by a finite-state controller, as is the case for Monte-Carlo Value Iteration [2], the belief is the controller state, which is a node in a graph. Another example is an agent represented by a recurrent neural network. In this case, the agent&#39;s belief is the state of the network. In order to accommodate a wide variety of decision-making approaches in POMDPs.jl, we use the term &quot;belief&quot; to denote the set of information that the agent makes a decision on, which could be an exact state distribution, an action-observation history, a set of weighted particles, or the examples mentioned before. In code, the belief can be represented by any built-in or user-defined type.</p><p>When an action is taken and a new observation is received, the belief is updated by the belief updater. In code, a belief updater is represented by a concrete subtype of the <a href="../api/#POMDPs.Updater"><code>Updater</code></a> abstract type, and the <a href="../api/#POMDPs.update"><code>update(updater, belief, action, observation)</code></a> function defines how the belief is updated when a new observation is received.</p><p>Although the agent may use a specialized belief structure to make decisions, the information initially given to the agent about the state of the problem is usually most conveniently represented as a state distribution, thus the <a href="../api/#POMDPs.initialize_belief"><code>initialize_belief</code></a> function is provided to convert a state distribution to a specialized belief structure that an updater can work with.</p><p>In many cases, the belief structure is closely related to the solution technique, so it will be implemented by the programmer who writes the solver. In other cases, the agent can use a variety of belief structures to make decisions, so a domain-specific updater implemented by the programmer that wrote the problem description may be appropriate. Finally, some advanced generic belief updaters such as particle filters may be implemented by a third party. The convenience function <a href="../api/#POMDPs.updater"><code>updater(policy)</code></a> can be used to get a suitable default updater for a policy, however many policies can work with other updaters.</p><p>For more information on implementing a belief updater, see <a href="../def_updater/#Defining-a-Belief-Updater">Defining a Belief Updater</a></p><h2 id="Solvers-and-Policies"><a class="docs-heading-anchor" href="#Solvers-and-Policies">Solvers and Policies</a><a id="Solvers-and-Policies-1"></a><a class="docs-heading-anchor-permalink" href="#Solvers-and-Policies" title="Permalink"></a></h2><p>Sequential decision making under uncertainty involves both online and offline calculations. In the broad sense, the term &quot;solver&quot; as used in the node in the figure at the top of the page refers to the software package that performs the calculations at both of these times. However, the code is broken up into two pieces, the solver that performs calculations offline and the policy that performs calculations online.</p><p>In the abstract, a policy is a mapping from every belief that an agent might take to an action. A policy is represented in code by a concrete subtype of the <a href="../api/#POMDPs.Policy"><code>Policy</code></a> abstract type. The programmer implements <a href="../api/#POMDPs.action"><code>action</code></a> to describe what computations need to be done online. For an online solver such as POMCP, all of the decision computation occurs within <a href="../api/#POMDPs.action"><code>action</code></a> while for an offline solver like SARSOP, there is very little computation within <a href="../api/#POMDPs.action"><code>action</code></a>. See <a href="../policy_interaction/#Interacting-with-Policies">Interacting with Policies</a> for more information.</p><p>The offline portion of the computation is carried out by the solver, which is represented by a concrete subtype of the <a href="../api/#POMDPs.Solver"><code>Solver</code></a> abstract type. Computations occur within the <a href="../api/#POMDPs.solve"><code>solve</code></a> function. For an offline solver like SARSOP, nearly all of the decision computation occurs within this function, but for some online solvers such as POMCP, <a href="../api/#POMDPs.solve"><code>solve</code></a> merely embeds the problem in the policy.</p><h2 id="Simulators"><a class="docs-heading-anchor" href="#Simulators">Simulators</a><a id="Simulators-1"></a><a class="docs-heading-anchor-permalink" href="#Simulators" title="Permalink"></a></h2><p>A simulator defines a way to run one or more simulations. It is represented by a concrete subtype of the <a href="../api/#POMDPs.Simulator"><code>Simulator</code></a> abstract type and the simulation is an implemention of <a href="../api/#POMDPs.simulate"><code>simulate</code></a>. Depending on the simulator, <a href="../api/#POMDPs.simulate"><code>simulate</code></a> may return a variety of data about the simulation, such as the discounted reward or the state history. All simulators should perform simulations consistent with the <a href="../simulation/#Simulation-Standard">Simulation Standard</a>.</p><p>[1] <em>Decision Making Under Uncertainty: Theory and Application</em> by Mykel J. Kochenderfer, MIT Press, 2015</p><p>[2] Bai, H., Hsu, D., &amp; Lee, W. S. (2014). Integrated perception and planning in the continuous space: A POMDP approach. The International Journal of Robotics Research, 33(9), 1288-1302</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../get_started/">« Getting Started</a><a class="docs-footer-nextpage" href="../def_pomdp/">Defining POMDPs and MDPs »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.1.2 on <span class="colophon-date" title="Wednesday 1 November 2023 21:58">Wednesday 1 November 2023</span>. Using Julia version 1.9.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
